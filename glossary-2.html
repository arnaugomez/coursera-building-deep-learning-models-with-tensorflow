<html>
  <head>
    <style>
      .linenums {
        list-style-type: none;
      }

      .formatted-line-numbers {
        display: none;
      }
      .action-code-block {
        display: none;
      }
      table {
        border-collapse: collapse;
        width: 100%;
      }
      table,
      th,
      td {
        border: 1px solid black;
        padding: 8px;
        text-align: left;
      }
    </style>
  </head>
  <body>
    <h1>
      <span class="header-link octicon octicon-link"></span>Module 3 Glossary:
      Transformers in Keras
    </h1>
    <p>
      Welcome! This alphabetized glossary contains many terms used in this
      course. Understanding these terms is essential when working in the
      industry, participating in user groups, and participating in other
      certificate programs.
    </p>
    <table>
      <thead>
        <tr>
          <th>Term</th>
          <th>Definition</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Autoregressive integrated moving average (ARIMA)</td>
          <td>
            A time series forecasting model that is used to predict future data
            points by combining three components: autoregression, differencing,
            and moving averages.
          </td>
        </tr>
        <tr>
          <td>
            Bidirectional Encoder Representations from Transformers (BERT)
          </td>
          <td>
            A deep learning model in which every output element is connected to
            every input element. The weightings between them are dynamically
            calculated based on their connection.
          </td>
        </tr>
        <tr>
          <td>Convolutional neural networks (CNNs)</td>
          <td>
            A type of deep learning model designed to process and analyze visual
            data by automatically detecting patterns through convolutional
            layers.
          </td>
        </tr>
        <tr>
          <td>Computer vision</td>
          <td>
            A field of AI that enables machines to interpret and understand
            visual information from various content such as images and videos.
          </td>
        </tr>
        <tr>
          <td>Cross-attention mechanism</td>
          <td>
            A model that allows the model to focus on relevant parts of the
            input sequence while generating output.
          </td>
        </tr>
        <tr>
          <td>Decoder</td>
          <td>
            A transformer decoder is a neural network architecture used in
            natural language processing tasks like machine translation and text
            generation. It generates output text by combining with an encoder to
            process input text.
          </td>
        </tr>
        <tr>
          <td>Deep learning</td>
          <td>
            A branch of artificial intelligence (AI). Deep learning is a subset
            of machine learning that uses large, multi-layered neural networks
            to automatically learn and make predictions from complex data.
          </td>
        </tr>
        <tr>
          <td>Embed</td>
          <td>
            In transformers, embedding is the technique of converting input
            tokens into dense, continuous vectors that represent their semantic
            meaning within the model.
          </td>
        </tr>
        <tr>
          <td>Encoder</td>
          <td>
            Encoders are neural network layers that process the input sequence
            and produce a continuous representation of the input. The
            transformer encoder architecture is the basis for many
            state-of-the-art models in natural language processing tasks.
          </td>
        </tr>
        <tr>
          <td>Generative pre-trained transformers (GPT)</td>
          <td>
            The neural network-based language prediction models that are built
            on the Transformer architecture. They analyze natural language
            queries, known as prompts, and predict the best possible response
            based on their understanding of language.
          </td>
        </tr>
        <tr>
          <td>Image recognition</td>
          <td>
            A software's ability to identify and classify people, objects,
            places, writing, and actions in digital images and video.
          </td>
        </tr>
        <tr>
          <td>Image processing</td>
          <td>
            A technique of manipulating and analyzing digital images to enhance,
            extract information, or convert them into a different format.
          </td>
        </tr>
        <tr>
          <td>Long short-term memory networks (LSTMs)</td>
          <td>
            A type of recurrent neural network (RNN) designed to capture and
            maintain long-term dependencies in sequential data.
          </td>
        </tr>
        <tr>
          <td>Layer normalization</td>
          <td>
            A technique used in Transformer neural networks to normalize the
            input values of all neurons in a layer for each data sample.
          </td>
        </tr>
        <tr>
          <td>Natural language generation</td>
          <td>
            The use of artificial intelligence to produce spoken or written
            human-like text.
          </td>
        </tr>
        <tr>
          <td>Natural language processing (NLP)</td>
          <td>
            Branch of artificial intelligence that enables computers to
            understand, manipulate, and generate human language (natural
            language).
          </td>
        </tr>
        <tr>
          <td>Parallelization</td>
          <td>
            In transformers, parallelization refers to the ability to process
            multiple elements of a sequence simultaneously, rather than
            sequentially, to speed up training and inference.
          </td>
        </tr>
        <tr>
          <td>Recurrent neural network (RNN)</td>
          <td>
            A deep learning model that is trained to process and convert a
            sequential data input into a specific sequential data output.
          </td>
        </tr>
        <tr>
          <td>Reinforcement learning</td>
          <td>
            An area of machine learning where an agent learns to make decisions
            by taking actions in an environment to maximize cumulative rewards.
          </td>
        </tr>
        <tr>
          <td>Self-attention mechanisms</td>
          <td>
            Mechanisms in transformers that allow each element of a sequence to
            dynamically focus on and weigh the importance of other elements in
            the sequence to capture context and dependencies.
          </td>
        </tr>
        <tr>
          <td>Sequence</td>
          <td>
            In transformers, a sequence refers to an ordered set of tokens, such
            as words, that are processed together as input to capture
            dependencies and contextual information across the entire sequence.
          </td>
        </tr>
        <tr>
          <td>Sequential data</td>
          <td>
            Data that is ordered in a specific sequence, where the arrangement
            of elements matters, such as time series, audio, or text.
          </td>
        </tr>
        <tr>
          <td>Speech recognition</td>
          <td>
            A technology that converts spoken language into text by analyzing
            and interpreting audio signals.
          </td>
        </tr>
        <tr>
          <td>Vision transformers (ViTs)</td>
          <td>
            A type of neural network architecture that applies transformer
            models to image analysis, treating image patches as sequences to
            capture visual patterns.
          </td>
        </tr>
        <tr>
          <td>Transformers</td>
          <td>
            A technology that can leverage self-attention mechanisms to process
            input data in parallel, making them highly efficient and powerful.
          </td>
        </tr>
      </tbody>
    </table>
    <p>
      <img
        src="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/ZzqKzMYvDxlItsE7xSlAXw.png"
        alt=""
      />
    </p>
  </body>
</html>
