<body>
  <h1>
    <span class="header-link octicon octicon-link"></span>Glossary: Advanced
    CNNs in Keras
  </h1>
  <p>
    Welcome! This alphabetized glossary contains many of the terms you'll find
    within this course. This comprehensive glossary also includes additional
    industry-recognized terms not used in course videos. These terms are
    important for you to recognize when working in the industry, participating
    in user groups, and participating in other certificate programs.
  </p>
  <p></p>
  <p></p>
  <table>
    <tbody>
      <tr>
        <th width="10%">Term</th>
        <th>Definition</th>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Activation function</b>
        </td>
        <td width="70%">
          A mathematical function used in neural networks to determine the
          output of a neuron.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Adam optimizer</b>
        </td>
        <td width="70%">
          An optimization algorithm that can be used instead of the classical
          stochastic gradient descent procedure to update network weights
          iteratively based on training data.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Augmentation</b>
        </td>
        <td width="70%">
          A process of increasing the diversity of training data by applying
          various transformations like rotation, scaling, and so on.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Binary cross-entropy</b>
        </td>
        <td width="70%">
          A loss function used for binary classification tasks, measuring the
          performance of a classification model whose output is a probability
          value between 0 and 1.
        </td>
      </tr>

      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Convolution</b>
        </td>
        <td width="70%">
          A mathematical operation used in deep learning, especially in
          convolutional neural networks (CNNs), for filtering data.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Custom augmentation function</b>
        </td>
        <td width="70%">
          A user-defined function that applies specific transformations to
          images during data augmentation, providing full control over the
          augmentation process.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Data augmentation</b>
        </td>
        <td width="70%">
          Techniques used to increase the diversity of training data by applying
          random transformations such as rotation, translation, flipping,
          scaling, and adding noise.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Deconvolution</b>
        </td>
        <td width="70%">
          Also known as transpose convolution, this is a technique used to
          up-sample an image, often used in generative models.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Dense layer</b>
        </td>
        <td width="70%">
          A fully connected neural network layer, where each input node is
          connected to each output node, commonly used in the final stages of a
          network.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Feature map</b>
        </td>
        <td width="70%">
          A set of features generated by applying a convolution operation to an
          image or data input.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Feature-wise normalization</b>
        </td>
        <td width="70%">
          A technique to set the mean of the data set to 0 and normalize it to
          have a standard deviation of 1.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Fine-tuning</b>
        </td>
        <td width="70%">
          The process of unfreezing some of the top layers of a pre-trained
          model base and jointly training both the newly added layers and the
          base layers for a specific task.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Flatten layer</b>
        </td>
        <td width="70%">
          A layer that converts the output of a convolutional layer to a 1D
          array, allowing it to be passed to a fully connected layer.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Generative adversarial networks (GANs)</b>
        </td>
        <td width="70%">
          A class of machine learning frameworks where two neural networks
          compete with each other to create realistic data samples.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Height shift range</b>
        </td>
        <td width="70%">
          A data augmentation parameter that randomly shifts an image
          vertically, altering its position to improve model robustness to
          vertical translations.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>TensorFlow Hub</b>
        </td>
        <td width="70%">
          A repository of reusable machine learning modules, which can be easily
          integrated into TensorFlow applications to accelerate development.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>TensorFlow.js</b>
        </td>
        <td width="70%">
          A library for training and deploying machine learning models in
          JavaScript environments, such as web browsers and Node.js.
        </td>
      </tr>
      <tr></tr>
      <tr>
        <td width="10%" valign="top">
          <b>Horizontal flip</b>
        </td>
        <td width="70%">
          A data augmentation technique where the image is flipped horizontally,
          creating a mirror image to increase data diversity.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>ImageDataGenerator</b>
        </td>
        <td width="70%">
          A Keras class used for generating batches of tensor image data with
          real-time data augmentation.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>ImageNet</b>
        </td>
        <td width="70%">
          A large visual database designed for use in visual object recognition
          software research, often used as a data set for pre-training
          convolutional neural networks.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Image processing</b>
        </td>
        <td width="70%">
          The manipulation of an image to improve its quality or extract
          information from it.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Kernel</b>
        </td>
        <td width="70%">
          A small matrix used in convolution operations to detect features such
          as edges in images.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Latent vector</b>
        </td>
        <td width="70%">
          A vector representing compressed data in a lower-dimensional space,
          often used in generative models.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Pre-trained model</b>
        </td>
        <td width="70%">
          A model previously trained on a large data set, which can be used as a
          starting point for training on a new, related task.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Random noise</b>
        </td>
        <td width="70%">
          A type of custom augmentation that adds random noise to images,
          simulating different lighting conditions and sensor noise to make
          models more robust.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Rotation range</b>
        </td>
        <td width="70%">
          A data augmentation parameter that randomly rotates an image within a
          specified range of degrees, enhancing model robustness to rotations.
        </td>
      </tr>
      <tr>
        <td width="10%" valign="top">
          <b>Sample-wise normalization</b>
        </td>
        <td width="70%">
          A technique to set the mean of each sample to 0 and normalize each
          sample to have a standard deviation of 1.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Semantic segmentation</b>
        </td>
        <td width="70%">
          A deep learning task that involves classifying each pixel in an image
          into a predefined class.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Shear range</b>
        </td>
        <td width="70%">
          A data augmentation parameter that applies a shear transformation to
          an image, slanting it along one axis to simulate different
          perspectives.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Stride</b>
        </td>
        <td width="70%">
          A parameter in convolution that determines the step size of the kernel
          when moving across the input data.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>TensorFlow</b>
        </td>
        <td width="70%">
          An open-source machine learning library used for various tasks,
          including deep learning and image processing.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Transfer learning</b>
        </td>
        <td width="70%">
          A method where a pre-trained model is adapted to a new, related task
          by adjusting its weights, allowing it to perform well even with
          limited data for the new task.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Transpose convolution</b>
        </td>
        <td width="70%">
          An operation that reverses the effects of convolution, often used for
          up-sampling in image processing.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>VGG16</b>
        </td>
        <td width="70%">
          A convolutional neural network model pre-trained on the ImageNet data
          set, commonly used in transfer learning for tasks involving image
          classification.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Width shift range</b>
        </td>
        <td width="70%">
          A data augmentation parameter that randomly shifts an image
          horizontally, altering its position to improve model robustness to
          horizontal translations.
        </td>
      </tr>

      <tr>
        <td width="10%" valign="top">
          <b>Zoom range</b>
        </td>
        <td width="70%">
          A data augmentation parameter that randomly zooms in or out on an
          image, altering its scale during training.
        </td>
      </tr>
    </tbody>
  </table>
  <footer>
    <p>
      <img
        src="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PDM321EN-SkillsNetwork/images/SNIBMfooter.png"
        alt=""
      />
    </p>
  </footer>
</body>
