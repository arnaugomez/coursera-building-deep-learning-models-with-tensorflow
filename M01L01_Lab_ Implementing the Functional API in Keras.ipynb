{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41132e46-33cf-4963-af3a-580521077382",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/BQm_EV6i0_j80CQZ8vcLvw/SN-web-lightmode.png\" width=300 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac321e-d96a-40e4-ac0e-3276218c8faf",
   "metadata": {},
   "source": [
    "## Lab: Implementing the Functional API in Keras \n",
    "\n",
    "**Estimated time needed: 30 minutes**\n",
    "\n",
    "In this lab, you will implement Keras functional API to build a neural network model. This lab will guide you through the steps of creating an input layer, adding hidden layers, and defining an output layer using the Functional API. \n",
    "\n",
    "##### Learning objectives: \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Use the Keras Functional API to build a simple neural network model. \n",
    "\n",
    "- Create an input layer, add hidden layers, and define an output layer using the Functional API. \n",
    "\n",
    "##### Prerequisites: \n",
    "\n",
    "- Basic understanding of Python programming \n",
    "\n",
    "- Familiarity with neural network concepts\n",
    "  \n",
    "- Keras and TensorFlow installed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f5313-70ea-4cbc-93d6-86bf73501947",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "**Step 1: Import Necessary Libraries**\n",
    "\n",
    "Before you start, make sure to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a6c9c6-fc07-471c-965e-57e8ac5d82d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.16.2\n",
      "  Using cached tensorflow-2.16.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow==2.16.2)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.16.2)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.16.2)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.16.2)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.16.2)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow==2.16.2)\n",
      "  Using cached h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.16.2)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.16.2)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.2) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.16.2)\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow==2.16.2)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.2) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.2) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.16.2)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.11/site-packages (from tensorflow==2.16.2) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow==2.16.2)\n",
      "  Using cached wrapt-1.17.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.16.2)\n",
      "  Using cached grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow==2.16.2)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.16.2)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.16.2)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.16.2)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Using cached optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow==2.16.2)\n",
      "  Using cached charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow==2.16.2)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow==2.16.2)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow==2.16.2)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.16.2-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\n",
      "Using cached h5py-3.12.1-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached wrapt-1.17.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.13.1-cp311-cp311-macosx_11_0_arm64.whl (318 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, absl-py, werkzeug, requests, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.12.14 charset-normalizer-3.4.0 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 idna-3.10 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opt-einsum-3.4.0 optree-0.13.1 protobuf-4.25.5 requests-2.32.3 rich-13.9.4 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.2 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow\n",
    "%pip install tensorflow==2.16.2\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eeb6d-246a-4201-93e5-7f27cd6023c3",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`!pip install tensorflow==2.16.2` installs the specified version of TensorFlow.\n",
    "\n",
    " `tensorflow` is the main library for machine learning in Python. \n",
    "\n",
    " `Model` is used to create a model with the Functional API. \n",
    "\n",
    " `Input` and `Dense` are types of layers that you will use in your model. \n",
    "\n",
    " \n",
    "**Step 2: Define the Input Layer**\n",
    "\n",
    "You will define the input shape for your model. For simplicity, let's assume you are working with a dataset where each input is a vector of length 20. \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45164301-2de9-469a-9815-7a574674d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 20), dtype=float32, sparse=False, name=keras_tensor>\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(20,))\n",
    "print(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4434c55-d73b-476c-acb9-17c633cf3817",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`Input(shape=(20,))` creates an input layer that expects input vectors of length 20.\n",
    "\n",
    "`print(input_layer)` shows the layer information, helping you understand the type of information you can get about the layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c5704-5ce4-4209-83f2-16915383e981",
   "metadata": {},
   "source": [
    "**Step 3: Add Hidden Layers**\n",
    "\n",
    "Next, you will add a couple of hidden layers to your model. Hidden layers help the model learn complex patterns in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40886bb5-ac4e-4b74-b83b-7aa0b6626e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer1 = Dense(64, activation='relu')(input_layer) \n",
    "hidden_layer2 = Dense(64, activation='relu')(hidden_layer1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d3d38-d6f8-43de-aaa8-9dd72ede15d6",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`Dense(64, activation='relu')` creates a dense (fully connected) layer with 64 units and ReLU activation function. \n",
    "\n",
    "Each hidden layer takes the output of the previous layer as its input. \n",
    "\n",
    "**Step 4: Define the Output Layer**\n",
    "\n",
    "Finally, you will define the output layer. Suppose you are working on a binary classification problem, so the output layer will have one unit with a sigmoid activation function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776dfb8a-afc0-4335-8033-9dbea0f39170",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8c587-3886-419f-8181-ab3e70df745a",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`Dense(1, activation='sigmoid')` creates a dense layer with 1 unit and a sigmoid activation function, suitable for binary classification. \n",
    "\n",
    "**Step 5: Create the Model**\n",
    "\n",
    "Now, you will create the model by specifying the input and output layers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02a84cd-0153-4518-b8f1-6a64e91af2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d5f6e-f968-4aed-892c-98733cdc30ef",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`Model(inputs=input_layer, outputs=output_layer)` creates a Keras model that connects the input layer to the output layer through the hidden layers. \n",
    "\n",
    "`model.summary()` provides a summary of the model, showing the layers, their shapes, and the number of parameters. This helps you interpret the model architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d633bd-dd59-437f-a248-4b8d79a27e21",
   "metadata": {},
   "source": [
    "**Step 6: Compile the Model**\n",
    "\n",
    "Before training the model, you need to compile it. You will specify the loss function, optimizer, and evaluation metrics. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea958130-2b3f-4c9f-a659-d59cc8ad69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d976c-71ce-43c2-80f8-67b9442a59d3",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`optimizer='adam'` specifies the Adam optimizer, a popular choice for training neural networks. \n",
    "\n",
    "`loss='binary_crossentropy'` specifies the loss function for binary classification problems. \n",
    "\n",
    "`metrics=['accuracy']` instructs Keras to evaluate the model using accuracy during training. \n",
    "\n",
    "**Step 7: Train the Model**\n",
    "\n",
    "You can now train the model using training data. For this example, let's assume `X_train` is your training input data and `y_train` is the corresponding label. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fec2add-af51-4b4d-b3e9-5e627016702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.5320 - loss: 0.6954 \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.5121 - loss: 0.6940\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.5353 - loss: 0.6884\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.5565 - loss: 0.6843\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.6077 - loss: 0.6797\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.5733 - loss: 0.6780\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.5804 - loss: 0.6789\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - accuracy: 0.6315 - loss: 0.6698\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - accuracy: 0.5974 - loss: 0.6697\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.6062 - loss: 0.6721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1754a6a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data (in practice, use real dataset) \n",
    "\n",
    "import numpy as np \n",
    "X_train = np.random.rand(1000, 20) \n",
    "y_train = np.random.randint(2, size=(1000, 1)) \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90be1b21-dd94-4f2a-8431-e35e1c4f2bed",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`X_train` and `y_train` are placeholders for your actual training data. \n",
    "\n",
    "`model.fit` trains the model for a specified number of epochs and batch size. \n",
    "\n",
    "**Step 8: Evaluate the Model**\n",
    "\n",
    "After training, you can evaluate the model on test data to see how well it performs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43d686e-8c08-4a4b-9f9d-7022d33fbde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5249 - loss: 0.6982 \n",
      "Test loss: 0.6882955431938171\n",
      "Test accuracy: 0.550000011920929\n"
     ]
    }
   ],
   "source": [
    "# Example test data (in practice, use real dataset) \n",
    "\n",
    "X_test = np.random.rand(200, 20) \n",
    "y_test = np.random.randint(2, size=(200, 1)) \n",
    "loss, accuracy = model.evaluate(X_test, y_test) \n",
    "print(f'Test loss: {loss}') \n",
    "print(f'Test accuracy: {accuracy}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a17eda-cc10-43c8-8f90-415a84f30f9c",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "`model.evaluate` computes the loss and accuracy of the model on test data. \n",
    "\n",
    "`X_test` and `y_test` are placeholders for your actual test data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67967e91-9931-4399-8333-94ef2eb66fb6",
   "metadata": {},
   "source": [
    "### Dropout and Batch Normalization\n",
    "\n",
    "Before we proceed with the practice exercise, let's briefly discuss two important techniques often used to improve the performance of neural networks: **Dropout Layers** and **Batch Normalization**.\n",
    "\n",
    "#### Dropout Layers\n",
    "\n",
    "Dropout is a regularization technique that helps prevent overfitting in neural networks. During training, Dropout randomly sets a fraction of input units to zero at each update cycle. This prevents the model from becoming overly reliant on any specific neurons, which encourages the network to learn more robust features that generalize better to unseen data.\n",
    "\n",
    "**Key points:**\n",
    "- Dropout is only applied during training, not during inference.\n",
    "- The dropout rate is a hyperparameter that determines the fraction of neurons to drop.\n",
    "\n",
    "\n",
    "#### Batch Normalization\n",
    "\n",
    "Batch Normalization is a technique used to improve the training stability and speed of neural networks. It normalizes the output of a previous layer by re-centering and re-scaling the data, which helps in stabilizing the learning process. By reducing the internal covariate shift (the changes in the distribution of layer inputs), batch normalization allows the model to use higher learning rates, which often speeds up convergence.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- Batch normalization works by normalizing the inputs to each layer to have a mean of zero and a variance of one.\n",
    "- It is applied during both training and inference, although its behavior varies slightly between the two phases.\n",
    "- Batch normalization layers also introduce two learnable parameters that allow the model to scale and - shift the normalized output, which helps in restoring the model's representational power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7da9c-bada-431e-a5f1-ca4d1eb35197",
   "metadata": {},
   "source": [
    "**Example of adding a Dropout layer in Keras:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e23cf5-ef9c-4701-8de5-870fe5305c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add a hidden layer\n",
    "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
    "\n",
    "# Add a Dropout layer\n",
    "dropout_layer = Dropout(rate=0.5)(hidden_layer)\n",
    "\n",
    "# Add another hidden layer after Dropout\n",
    "hidden_layer2 = Dense(64, activation='relu')(dropout_layer)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384190b-ed08-41a6-8786-2bcd7b309921",
   "metadata": {},
   "source": [
    "**Example of adding Batch Normalization in Keras:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a4d2c-19bd-4d29-b78e-8b5cf6d4e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add a hidden layer\n",
    "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
    "\n",
    "# Add a BatchNormalization layer\n",
    "batch_norm_layer = BatchNormalization()(hidden_layer)\n",
    "\n",
    "# Add another hidden layer after BatchNormalization\n",
    "hidden_layer2 = Dense(64, activation='relu')(batch_norm_layer)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b10de4-bfc4-459e-8b1a-ba4eee7e9b9c",
   "metadata": {},
   "source": [
    "### Practice exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df2827-1728-4d09-bc04-22f7450ae8b4",
   "metadata": {},
   "source": [
    "#### Exercise 1: Add Dropout Layers\n",
    "\n",
    "**Objective:** Learn to add dropout layers to prevent overfitting.\n",
    "\n",
    "**Instructions:**\n",
    "1. Add dropout layers after each hidden layer in the model.\n",
    "2. Set the dropout rate to 0.5.\n",
    "3. Recompile, train, and evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7cc943f-cc09-4c42-994f-8ee068885e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.5201 - loss: 0.7289 \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.5140 - loss: 0.7042\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.4857 - loss: 0.7116\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.4863 - loss: 0.7062\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.5157 - loss: 0.6972\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.4716 - loss: 0.6988\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.5125 - loss: 0.6927\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.5325 - loss: 0.6885\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.5170 - loss: 0.6925\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.5629 - loss: 0.6838\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 0.6932 \n",
      "Test loss: 0.6940852999687195\n",
      "Test accuracy: 0.49000000953674316\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add a hidden layer\n",
    "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
    "\n",
    "# Add a Dropout layer\n",
    "dropout_layer = Dropout(rate=0.5)(hidden_layer)\n",
    "\n",
    "# Add another hidden layer after Dropout\n",
    "hidden_layer2 = Dense(64, activation='relu')(dropout_layer)\n",
    "\n",
    "dropout_layer2 = Dropout(rate=0.5)(hidden_layer2)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(1000, 20) \n",
    "y_train = np.random.randint(2, size=(1000, 1)) \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32) \n",
    "\n",
    "X_test = np.random.rand(200, 20) \n",
    "y_test = np.random.randint(2, size=(200, 1)) \n",
    "loss, accuracy = model.evaluate(X_test, y_test) \n",
    "print(f'Test loss: {loss}') \n",
    "print(f'Test accuracy: {accuracy}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40831fe-9ff0-4584-920b-4fb2170e6766",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add hidden layers with dropout\n",
    "hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "dropout1 = Dropout(0.5)(hidden_layer1)\n",
    "hidden_layer2 = Dense(64, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(hidden_layer2)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    " ```   \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7160b-78d1-4fb6-89d0-07ad0c667830",
   "metadata": {},
   "source": [
    "#### Exercise 2: Change Activation Functions\n",
    "\n",
    "**Objective:** Experiment with different activation functions.\n",
    "\n",
    "**Instructions:**\n",
    "1. Change the activation function of the hidden layers from ReLU to Tanh.\n",
    "2. Recompile, train, and evaluate the model to see the effect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9767e43d-327c-4884-aa7d-fecdcebaff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,569</span> (21.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,569\u001b[0m (21.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.4793 - loss: 0.7673 \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.5218 - loss: 0.7410\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.5255 - loss: 0.7143\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.4972 - loss: 0.7332\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.5396 - loss: 0.7064\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.5065 - loss: 0.7219\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.4653 - loss: 0.7219\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.5657 - loss: 0.6855\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.5202 - loss: 0.6978\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5162 - loss: 0.7027\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.6956 \n",
      "Test loss: 0.6925203800201416\n",
      "Test accuracy: 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "## Write your code here\n",
    "from tensorflow.keras.layers import Dropout, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np \n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add a hidden layer\n",
    "hidden_layer = Dense(64, activation='tanh')(input_layer)\n",
    "\n",
    "# Add a Dropout layer\n",
    "dropout_layer = Dropout(rate=0.5)(hidden_layer)\n",
    "\n",
    "# Add another hidden layer after Dropout\n",
    "hidden_layer2 = Dense(64, activation='tanh')(dropout_layer)\n",
    "\n",
    "dropout_layer2 = Dropout(rate=0.5)(hidden_layer2)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(1000, 20) \n",
    "y_train = np.random.randint(2, size=(1000, 1)) \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32) \n",
    "\n",
    "X_test = np.random.rand(200, 20) \n",
    "y_test = np.random.randint(2, size=(200, 1)) \n",
    "loss, accuracy = model.evaluate(X_test, y_test) \n",
    "print(f'Test loss: {loss}') \n",
    "print(f'Test accuracy: {accuracy}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a389c-9617-48b3-b93d-0361045a8e9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add hidden layers with Tanh activation\n",
    "hidden_layer1 = Dense(64, activation='tanh')(input_layer)\n",
    "hidden_layer2 = Dense(64, activation='tanh')(hidden_layer1)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    " ```   \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a87b7-1ef0-4346-a15b-58dc3266eebe",
   "metadata": {},
   "source": [
    "#### Exercise 3: Use Batch Normalization\n",
    "\n",
    "**Objective:** Implement batch normalization to improve training stability.\n",
    "\n",
    "**Instructions:**\n",
    "1. Add batch normalization layers after each hidden layer.\n",
    "2. Recompile, train, and evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39460850-e14e-4f04-b9f0-404ba44b96a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,081</span> (23.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,081\u001b[0m (23.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,825</span> (22.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,825\u001b[0m (22.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.4747 - loss: 0.8777 \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.5321 - loss: 0.7348\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.6217 - loss: 0.6522\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.6215 - loss: 0.6406\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.6698 - loss: 0.6166\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.6887 - loss: 0.5833\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.6974 - loss: 0.5778\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7340 - loss: 0.5636\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7084 - loss: 0.5565\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.7182 - loss: 0.5518\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5671 - loss: 0.6763 \n",
      "Test loss: 0.6968759298324585\n",
      "Test accuracy: 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add a hidden layer\n",
    "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
    "\n",
    "# Add a BatchNormalization layer\n",
    "batch_norm_layer = BatchNormalization()(hidden_layer)\n",
    "\n",
    "# Add another hidden layer after Dropout\n",
    "hidden_layer2 = Dense(64, activation='relu')(batch_norm_layer)\n",
    "\n",
    "# Add a BatchNormalization layer\n",
    "batch_norm_layer2 = BatchNormalization()(hidden_layer2)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(batch_norm_layer2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(1000, 20) \n",
    "y_train = np.random.randint(2, size=(1000, 1)) \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32) \n",
    "\n",
    "X_test = np.random.rand(200, 20) \n",
    "y_test = np.random.randint(2, size=(200, 1)) \n",
    "loss, accuracy = model.evaluate(X_test, y_test) \n",
    "print(f'Test loss: {loss}') \n",
    "print(f'Test accuracy: {accuracy}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508089c-d7b5-482a-9d3e-c09aacab4530",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(20,))\n",
    "\n",
    "# Add hidden layers with batch normalization\n",
    "hidden_layer1 = Dense(64, activation='relu')(input_layer)\n",
    "batch_norm1 = BatchNormalization()(hidden_layer1)\n",
    "hidden_layer2 = Dense(64, activation='relu')(batch_norm1)\n",
    "batch_norm2 = BatchNormalization()(hidden_layer2)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(batch_norm2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')\n",
    " ```   \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1343de9-8535-40e6-b530-8325b0a4f538",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "By completing these exercises, students will:\n",
    "\n",
    "1. Understand the impact of dropout layers on model overfitting.\n",
    "2. Learn how different activation functions affect model performance.\n",
    "3. Gain experience with batch normalization to stabilize and accelerate training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f6753-ff96-4a46-8cd9-4a67f5849423",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "You have successfully created, trained, and evaluated a simple neural network model using the Keras Functional API. This foundational knowledge will allow you to build more complex models and explore advanced functionalities in Keras. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab0729-d88a-4ca9-8437-4ce9ed3da07b",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "6c06f1b1d27897bfab0879abc1416612866b18c633f234331540b14850c06c25"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
